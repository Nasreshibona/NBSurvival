{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,RandomizedSearchCV,cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler,RobustScaler\n",
    "from sklearn.utils import shuffle\n",
    "from scipy.sparse import coo_matrix\n",
    "from sklearn.feature_selection import SelectKBest,chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct training-set\n",
    "co = pd.read_csv('../outputs/log-counts.tsv', sep='\\t', encoding = \"ISO-8859-1\")\n",
    "co = co.set_index('ensembl_Id')\n",
    "tp = pd.read_csv('../outputs/dge/top_up.csv', sep=',', encoding = \"ISO-8859-1\")\n",
    "dw = pd.read_csv('../outputs/dge/top_down.csv', sep=',', encoding = \"ISO-8859-1\")\n",
    "ts = pd.read_csv(\"../outputs/camda-test-set-82.csv\")\n",
    "ts = ts.set_index('sample_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for i, b in enumerate(tp['symbol'].notnull()):\n",
    "    if b:\n",
    "        transcript = tp['transcriptId'].iloc[i]\n",
    "        gene = tp['symbol'].iloc[i]\n",
    "        if gene in list(ts.columns):\n",
    "            df[gene] = co.loc[transcript]\n",
    "        \n",
    "for i, b in enumerate(dw['symbol'].notnull()):\n",
    "    if b:\n",
    "        transcript = dw['transcriptId'].iloc[i]\n",
    "        gene = dw['symbol'].iloc[i]\n",
    "        if gene in list(ts.columns):\n",
    "            df[gene] = co.loc[transcript]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = []\n",
    "for i, _ in df.iterrows():\n",
    "    if i.startswith('ss'):\n",
    "        target.append(0)\n",
    "    else:\n",
    "        target.append(1)\n",
    "        \n",
    "df['target'] = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 17)"
      ]
     },
     "execution_count": 767,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ANN ML ##\n",
    "X = df.iloc[:, :16]\n",
    "y = df.iloc[:, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best features are:['EVX2', 'NHLH2', 'PRSS12', 'POU6F2', 'MAPK15', 'RTL1', 'LGR5', 'DPY19L2P4', 'STRA6', 'CYP17A1', 'OR10AB1P', 'LRRTM3', 'HIST1H1E', 'NXPH3', 'MYL3']\n",
      "The eliminated features are:['HOXD10', 'MYH14', 'GRIN3A', 'HS3ST5', 'NBAS', 'CRYAB', 'CMYA5', 'AMIGO2', 'EDIL3', 'UBC']\n"
     ]
    }
   ],
   "source": [
    "# Feature selection - ***SKIP***\n",
    "X = SelectKBest(chi2, k=15).fit(X, y)\n",
    "mask = X.get_support()\n",
    "new_feat = []\n",
    "el_feat = []\n",
    "for bool, feature in zip(mask, df.columns):\n",
    "    if bool:\n",
    "        new_feat.append(feature)\n",
    "    else:\n",
    "        el_feat.append(feature)\n",
    "print('The best features are:{}'.format(new_feat))\n",
    "print('The eliminated features are:{}'.format(el_feat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sparse = coo_matrix(X)\n",
    "X, X_sparse, y = shuffle(X, X_sparse, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.875\n",
      "{'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': 6, 'max_iter': 10000, 'random_state': 0, 'solver': 'sgd'}\n"
     ]
    }
   ],
   "source": [
    "# Tuning Hyperparameters - SKIP\n",
    "parameters = {'solver': ['adam','lbfgs','sgd'],\n",
    "              'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "              'max_iter': [10000], \n",
    "              'alpha': [0.01,0.1],\n",
    "              'hidden_layer_sizes':[6,12,24,48,100],\n",
    "              'random_state':[0,1,2,3,4]}\n",
    "\n",
    "mlp = GridSearchCV(MLPClassifier(), parameters, n_jobs=-1, cv=5,iid=False)\n",
    "mlp = mlp.fit(X, y)\n",
    "print(mlp.score(X, y))\n",
    "print(mlp.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit ML\n",
    "#mlp = MLPClassifier(hidden_layer_sizes=(10,),activation='relu',solver='sgd',max_iter=7000, random_state=2,alpha=0.1)\n",
    "#mlp = MLPClassifier(hidden_layer_sizes=(24,24,24),activation='relu',solver='sgd',max_iter=10000,random_state=3,alpha=0.01)\n",
    "#mlp = MLPClassifier(hidden_layer_sizes=(6,),activation='identity',solver='adam',max_iter=10000,random_state=2,alpha=0.01)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(6,),activation='relu',solver='sgd',max_iter=10000,random_state=0,alpha=0.1)# test-set-1 82%\n",
    "#mlp = MLPClassifier(hidden_layer_sizes=(24,),activation='relu',solver='sgd',max_iter=10000,random_state=2,alpha=0.01)# test-set-1 82%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = mlp.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test ML\n",
    "X_test = ts.iloc[:, :16]\n",
    "y_test = ts.iloc[:, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[37  5]\n",
      " [ 6 13]]\n",
      "0.819672131147541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87        42\n",
      "           1       0.72      0.68      0.70        19\n",
      "\n",
      "   micro avg       0.82      0.82      0.82        61\n",
      "   macro avg       0.79      0.78      0.79        61\n",
      "weighted avg       0.82      0.82      0.82        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_test = mlp.predict(X_test)\n",
    "print(confusion_matrix(y_test, predict_test))\n",
    "print(accuracy_score(y_test, predict_test))\n",
    "print(classification_report(y_test, predict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SVM ML ##\n",
    "from libsvm.svmutil import *\n",
    "from sklearn.datasets import dump_svmlight_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_svmlight_file(X,y,'../outputs/svm/camda.svm', zero_based=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_svmlight_file(X_test,y_test,'../outputs/svm/camda-test.svm', zero_based=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use these command lines to scale and tune hyperparameters\n",
    "# ./libsvm-3.23/svm-scale -l 0 -u 1 -s t.scale camda.svm > camda.scale\n",
    "# ./libsvm-3.23/svm-scale -r t.scale camda-test.svm > camda-test.scale\n",
    "# ./libsvm-3.23/tools/grid.py camda.scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, X = svm_read_problem(\"../outputs/svm/camda.scale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracy = 78.125%\n"
     ]
    }
   ],
   "source": [
    "cross_val_accuracy = svm_train(y, X, '-c 32.0 -g 0.0078125 -t 2 -v 5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test, X_test = svm_read_problem(\"../outputs/svm/camda-test.scale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm_train(y, X, '-c 32.0 -t 2 -g 0.0078125')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 78.6885% (48/61) (classification)\n"
     ]
    }
   ],
   "source": [
    "p_label, p_acc, p_val = svm_predict(y_test, X_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.81      0.84        42\n",
      "         1.0       0.64      0.74      0.68        19\n",
      "\n",
      "   micro avg       0.79      0.79      0.79        61\n",
      "   macro avg       0.75      0.77      0.76        61\n",
      "weighted avg       0.80      0.79      0.79        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, p_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<svm.svm_model at 0x7f17cbc3ebf8>"
      ]
     },
     "execution_count": 718,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RandomForest - Feature selection ##\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 50, num = 40)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(1, 20, num=20)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2,3,4,5]\n",
    "min_samples_leaf = [1,2,3]\n",
    "bootstrap = [True, False]\n",
    "random_state = [int(x) for x in np.linspace(0,50, num=50)]\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap,\n",
    "               'random_state': random_state}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:    4.0s finished\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, \n",
    "                               n_iter = 100, cv = 5, verbose=2, n_jobs = -1, iid=False)\n",
    "mlp = rf_random.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'random_state': 20,\n",
       " 'n_estimators': 39,\n",
       " 'min_samples_split': 3,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 4,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.71428571, 0.71428571, 0.83333333, 0.83333333, 1.        ])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mlp = rf_random.best_estimator_ \n",
    "#mlp = RandomForestClassifier(n_jobs=-1,random_state=24,n_estimators=36,\n",
    "#                            min_samples_split=3,min_samples_leaf=3,\n",
    "#                            max_features='auto',max_depth=9,bootstrap=True)\n",
    "\n",
    "mlp = RandomForestClassifier(n_jobs=-1,random_state=0,n_estimators=100,\n",
    "                            min_samples_split=4,min_samples_leaf=4,\n",
    "                            max_features='sqrt',max_depth=7,bootstrap=True)\n",
    "\n",
    "# X and y are from ANN (Not SVM)\n",
    "cross_val_score(mlp, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7540983606557377"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = mlp.fit(X, y)\n",
    "preds = mlp.predict(X_test)\n",
    "mlp.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: DPY19L2P4  Importance: 0.14\n",
      "Variable: EDIL3      Importance: 0.1\n",
      "Variable: STRA6      Importance: 0.08\n",
      "Variable: LGR5       Importance: 0.07\n",
      "Variable: LRRTM3     Importance: 0.07\n",
      "Variable: NXPH3      Importance: 0.07\n",
      "Variable: MYL3       Importance: 0.07\n",
      "Variable: UBC        Importance: 0.07\n",
      "Variable: RTL1       Importance: 0.06\n",
      "Variable: NHLH2      Importance: 0.04\n",
      "Variable: HS3ST5     Importance: 0.04\n",
      "Variable: HIST1H1E   Importance: 0.03\n",
      "Variable: EVX2       Importance: 0.02\n",
      "Variable: PRSS12     Importance: 0.02\n",
      "Variable: MAPK15     Importance: 0.02\n",
      "Variable: CYP17A1    Importance: 0.02\n",
      "Variable: CRYAB      Importance: 0.02\n",
      "Variable: AMIGO2     Importance: 0.02\n",
      "Variable: GRIN3A     Importance: 0.01\n",
      "Variable: NBAS       Importance: 0.01\n",
      "Variable: POU6F2     Importance: 0.0\n",
      "Variable: HOXD10     Importance: 0.0\n",
      "Variable: OR10AB1P   Importance: 0.0\n",
      "Variable: MYH14      Importance: 0.0\n",
      "Variable: CMYA5      Importance: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = list(mlp.feature_importances_)\n",
    "feature_list = list(df.columns)\n",
    "feature_importances = [(f, round(i, 2)) for f, i in zip(feature_list, importances)]\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "[print('Variable: {:10} Importance: {}'.format(*pair)) for pair in feature_importances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
